{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjshrd/dementia_audio_classifier/blob/main/binary_audio_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-whaT3U7M1P0",
        "outputId": "66ba89d9-d661-47d6-8aae-953301397bd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.37.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.26.4)\n",
            "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
            "  Downloading numpy_minmax-0.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
            "  Downloading numpy_rms-0.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.2.post1)\n",
            "Collecting scipy<1.13,>=1.4 (from audiomentations)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2024.8.30)\n",
            "Downloading audiomentations-0.37.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy_minmax-0.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading numpy_rms-0.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17 kB)\n",
            "Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, numpy-rms, numpy-minmax, audiomentations\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed audiomentations-0.37.0 numpy-minmax-0.3.1 numpy-rms-0.4.2 scipy-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdDJUBX_Ow04",
        "outputId": "9514bef7-b325-49c4-e4c9-c07f71726595"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def extract_features(file_path, max_pad_len=128):\n",
        "    try:\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File does not exist: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        # Load audio file with librosa\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None, mono=True, res_type='kaiser_fast', duration=5)\n",
        "\n",
        "        # Verify audio has been loaded\n",
        "        if audio is None or len(audio) == 0:\n",
        "            print(f\"Unable to load audio from file: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        # Extract mel-spectrogram\n",
        "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=128, fmax=sample_rate/2)\n",
        "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "        # Pad or truncate spectrogram to max_pad_len\n",
        "        if spectrogram.shape[1] < max_pad_len:\n",
        "            pad_width = max_pad_len - spectrogram.shape[1]\n",
        "            spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            spectrogram = spectrogram[:, :max_pad_len]\n",
        "\n",
        "        # Expand dimensions to match expected input format for CNN (num_mels, time_steps, 1)\n",
        "        spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
        "\n",
        "        return spectrogram\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while parsing file: {file_path}\")\n",
        "        print(f\"Error details: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_data(csv_path):\n",
        "    df = pd.read_csv(csv_path, sep='\\t')\n",
        "    print(f\"Loaded dataframe shape: {df.shape}\")\n",
        "    print(df.columns)  # Print column names\n",
        "    print(df.head())   # Print first few rows\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    features = []\n",
        "    for index, row in df.iterrows():\n",
        "        file_path = row['path']\n",
        "        class_label = row['label']\n",
        "        data = extract_features(file_path)\n",
        "        if data is not None:\n",
        "            features.append([data, class_label])\n",
        "        else:\n",
        "            print(f\"Skipping file due to extraction error: {file_path}\")\n",
        "\n",
        "    print(f\"Processed {len(features)} files successfully out of {len(df)} total files\")\n",
        "    return features\n",
        "\n",
        "def prepare_dataset(features):\n",
        "    if not features:\n",
        "        raise ValueError(\"No features were successfully extracted from the dataset.\")\n",
        "\n",
        "    X = np.array([feature[0] for feature in features])\n",
        "    y = np.array([feature[1] for feature in features])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    print(f\"Prepared dataset shapes: X: {X.shape}, y: {y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=16):\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=(X_val, y_val))\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print(f'\\nTest accuracy: {test_acc}')\n",
        "    return test_acc\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = load_data('/content/drive/MyDrive/type3/data/train_dm.csv')\n",
        "    val_df = load_data('/content/drive/MyDrive/type3/data/valid_dm.csv')\n",
        "\n",
        "    # Preprocess data\n",
        "    train_features = preprocess_data(train_df)\n",
        "    val_features = preprocess_data(val_df)\n",
        "\n",
        "    # Prepare datasets\n",
        "    try:\n",
        "        X_train, y_train = prepare_dataset(train_features)\n",
        "        X_val, y_val = prepare_dataset(val_features)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error preparing dataset: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Build and train the model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)  # (num_mels, time_steps, 1)\n",
        "    print(f\"Input shape: {input_shape}\")\n",
        "\n",
        "    model = build_model(input_shape)\n",
        "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_accuracy = evaluate_model(model, X_val, y_val)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('audio_classifier_model.h5')\n",
        "\n",
        "    print(f'Model training completed. Validation accuracy: {val_accuracy}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gz9m7UoSEhc",
        "outputId": "d56638ac-911c-4c31-ac53-257ebae9bfec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataframe shape: (186, 3)\n",
            "Index(['file', 'label', 'path'], dtype='object')\n",
            "              file     label  \\\n",
            "0  TrevorPeacock_5  dementia   \n",
            "1  RonaldReagan_10  dementia   \n",
            "2   RonaldReagan_5  dementia   \n",
            "3     AbeBurrows_5  dementia   \n",
            "4      PeterMax_15  dementia   \n",
            "\n",
            "                                                path  \n",
            "0  /content/drive/My Drive/type3/data/dementia/Tr...  \n",
            "1  /content/drive/My Drive/type3/data/dementia/Ro...  \n",
            "2  /content/drive/My Drive/type3/data/dementia/Ro...  \n",
            "3  /content/drive/My Drive/type3/data/dementia/Ab...  \n",
            "4  /content/drive/My Drive/type3/data/dementia/Pe...  \n",
            "Loaded dataframe shape: (38, 3)\n",
            "Index(['file', 'label', 'path'], dtype='object')\n",
            "               file     label  \\\n",
            "0   EstelleGetty_15  dementia   \n",
            "1      CaseyKasem_5  dementia   \n",
            "2     CaseyKasem_15  dementia   \n",
            "3  JimmyFratianno_0  dementia   \n",
            "4         bbking_10  dementia   \n",
            "\n",
            "                                                path  \n",
            "0  /content/drive/My Drive/type3/data/dementia/Es...  \n",
            "1  /content/drive/My Drive/type3/data/dementia/Ca...  \n",
            "2  /content/drive/My Drive/type3/data/dementia/Ca...  \n",
            "3  /content/drive/My Drive/type3/data/dementia/Ji...  \n",
            "4  /content/drive/My Drive/type3/data/dementia/B ...  \n",
            "Processed 186 files successfully out of 186 total files\n",
            "Processed 38 files successfully out of 38 total files\n",
            "Prepared dataset shapes: X: (186, 128, 128, 1), y: (186,)\n",
            "Prepared dataset shapes: X: (38, 128, 128, 1), y: (38,)\n",
            "Input shape: (128, 128, 1)\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 414ms/step - accuracy: 0.5761 - loss: 24.1984 - val_accuracy: 0.5263 - val_loss: 0.7044\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 698ms/step - accuracy: 0.5737 - loss: 0.7165 - val_accuracy: 0.5263 - val_loss: 0.6943\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.6287 - loss: 0.6775 - val_accuracy: 0.6053 - val_loss: 0.6893\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 389ms/step - accuracy: 0.6491 - loss: 0.6709 - val_accuracy: 0.5789 - val_loss: 0.8426\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 659ms/step - accuracy: 0.7081 - loss: 0.6121 - val_accuracy: 0.5526 - val_loss: 0.6809\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 404ms/step - accuracy: 0.7662 - loss: 0.5998 - val_accuracy: 0.5263 - val_loss: 0.6907\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 383ms/step - accuracy: 0.5309 - loss: 0.6915 - val_accuracy: 0.5263 - val_loss: 0.6918\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 623ms/step - accuracy: 0.5868 - loss: 0.6865 - val_accuracy: 0.5263 - val_loss: 0.6918\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.5552 - loss: 0.6885 - val_accuracy: 0.5263 - val_loss: 0.6918\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 569ms/step - accuracy: 0.6312 - loss: 0.6786 - val_accuracy: 0.5263 - val_loss: 0.6919\n",
            "2/2 - 0s - 154ms/step - accuracy: 0.5263 - loss: 0.6919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 0.5263158082962036\n",
            "Model training completed. Validation accuracy: 0.5263158082962036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "import os\n",
        "from audiomentations import Compose, AddBackgroundNoise, Shift, PitchShift, TimeStretch\n",
        "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "BACKGROUND_NOISE_PATH = '/content/drive/MyDrive/type3/data/'  # for audio augmentation\n",
        "\n",
        "# Data augmentation setup\n",
        "augment = Compose([\n",
        "    AddBackgroundNoise(sounds_path=BACKGROUND_NOISE_PATH, p=0.5),\n",
        "    Shift(p=0.5),\n",
        "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5)\n",
        "])\n",
        "\n",
        "def extract_features(file_path, max_pad_len=128):\n",
        "    try:\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File does not exist: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        # Load audio file with librosa\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None, mono=True, res_type='kaiser_fast', duration=5)\n",
        "\n",
        "        # Verify audio has been loaded\n",
        "        if audio is None or len(audio) == 0:\n",
        "            print(f\"Unable to load audio from file: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        # Extract mel-spectrogram\n",
        "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=128, fmax=sample_rate/2)\n",
        "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "        # Pad or truncate spectrogram to max_pad_len\n",
        "        if spectrogram.shape[1] < max_pad_len:\n",
        "            pad_width = max_pad_len - spectrogram.shape[1]\n",
        "            spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            spectrogram = spectrogram[:, :max_pad_len]\n",
        "\n",
        "        # Expand dimensions to match expected input format for CNN (num_mels, time_steps, 1)\n",
        "        spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
        "\n",
        "        return spectrogram\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while parsing file: {file_path}\")\n",
        "        print(f\"Error details: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_data(csv_path):\n",
        "    df = pd.read_csv(csv_path, sep='\\t')\n",
        "    print(f\"Loaded dataframe shape: {df.shape}\")\n",
        "    print(df.columns)  # Print column names\n",
        "    print(df.head())   # Print first few rows\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    features = []\n",
        "    for index, row in df.iterrows():\n",
        "        file_path = row['path']\n",
        "        class_label = row['label']\n",
        "        data = extract_features(file_path)\n",
        "        if data is not None:\n",
        "            features.append([data, class_label])\n",
        "        else:\n",
        "            print(f\"Skipping file due to extraction error: {file_path}\")\n",
        "\n",
        "    print(f\"Processed {len(features)} files successfully out of {len(df)} total files\")\n",
        "    return features\n",
        "\n",
        "def prepare_dataset(features):\n",
        "    if not features:\n",
        "        raise ValueError(\"No features were successfully extracted from the dataset.\")\n",
        "\n",
        "    X = np.array([feature[0] for feature in features])\n",
        "    y = np.array([feature[1] for feature in features])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    print(f\"Prepared dataset shapes: X: {X.shape}, y: {y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=20, batch_size=8):\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=(X_val, y_val))\n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print(f'\\nTest accuracy: {test_acc}')\n",
        "    return test_acc\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = load_data('/content/drive/MyDrive/type3/data/train_dm.csv')\n",
        "    val_df = load_data('/content/drive/MyDrive/type3/data/valid_dm.csv')\n",
        "\n",
        "    # Preprocess data\n",
        "    train_features = preprocess_data(train_df)\n",
        "    val_features = preprocess_data(val_df)\n",
        "\n",
        "    # Prepare datasets\n",
        "    try:\n",
        "        X_train, y_train = prepare_dataset(train_features)\n",
        "        X_val, y_val = prepare_dataset(val_features)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error preparing dataset: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Build and train the model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)  # (num_mels, time_steps, 1)\n",
        "    print(f\"Input shape: {input_shape}\")\n",
        "\n",
        "    model = build_model(input_shape)\n",
        "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_accuracy = evaluate_model(model, X_val, y_val)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('audio_classifier_model.h5')\n",
        "\n",
        "    print(f'Model training completed. Validation accuracy: {val_accuracy}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xlmzxYJY3ii",
        "outputId": "6f65cac8-aea9-4687-9cf8-f8d49f0b910e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataframe shape: (186, 3)\n",
            "Index(['file', 'label', 'path'], dtype='object')\n",
            "              file     label  \\\n",
            "0  TrevorPeacock_5  dementia   \n",
            "1  RonaldReagan_10  dementia   \n",
            "2   RonaldReagan_5  dementia   \n",
            "3     AbeBurrows_5  dementia   \n",
            "4      PeterMax_15  dementia   \n",
            "\n",
            "                                                path  \n",
            "0  /content/drive/My Drive/type3/data/dementia/Tr...  \n",
            "1  /content/drive/My Drive/type3/data/dementia/Ro...  \n",
            "2  /content/drive/My Drive/type3/data/dementia/Ro...  \n",
            "3  /content/drive/My Drive/type3/data/dementia/Ab...  \n",
            "4  /content/drive/My Drive/type3/data/dementia/Pe...  \n",
            "Loaded dataframe shape: (38, 3)\n",
            "Index(['file', 'label', 'path'], dtype='object')\n",
            "               file     label  \\\n",
            "0   EstelleGetty_15  dementia   \n",
            "1      CaseyKasem_5  dementia   \n",
            "2     CaseyKasem_15  dementia   \n",
            "3  JimmyFratianno_0  dementia   \n",
            "4         bbking_10  dementia   \n",
            "\n",
            "                                                path  \n",
            "0  /content/drive/My Drive/type3/data/dementia/Es...  \n",
            "1  /content/drive/My Drive/type3/data/dementia/Ca...  \n",
            "2  /content/drive/My Drive/type3/data/dementia/Ca...  \n",
            "3  /content/drive/My Drive/type3/data/dementia/Ji...  \n",
            "4  /content/drive/My Drive/type3/data/dementia/B ...  \n",
            "Processed 186 files successfully out of 186 total files\n",
            "Processed 38 files successfully out of 38 total files\n",
            "Prepared dataset shapes: X: (186, 128, 128, 1), y: (186,)\n",
            "Prepared dataset shapes: X: (38, 128, 128, 1), y: (38,)\n",
            "Input shape: (128, 128, 1)\n",
            "Epoch 1/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 434ms/step - accuracy: 0.4646 - loss: 0.9607 - val_accuracy: 0.4737 - val_loss: 0.6996\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 399ms/step - accuracy: 0.5308 - loss: 0.8674 - val_accuracy: 0.5263 - val_loss: 0.7173\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 372ms/step - accuracy: 0.5503 - loss: 0.7844 - val_accuracy: 0.4474 - val_loss: 0.7009\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - accuracy: 0.5206 - loss: 0.8313 - val_accuracy: 0.4474 - val_loss: 0.6970\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 441ms/step - accuracy: 0.5806 - loss: 0.7585 - val_accuracy: 0.5263 - val_loss: 0.6937\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 310ms/step - accuracy: 0.4245 - loss: 0.9830 - val_accuracy: 0.5789 - val_loss: 0.6902\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 336ms/step - accuracy: 0.5316 - loss: 0.8471 - val_accuracy: 0.5000 - val_loss: 0.6978\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 540ms/step - accuracy: 0.4241 - loss: 0.9810 - val_accuracy: 0.4737 - val_loss: 0.7323\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 634ms/step - accuracy: 0.5594 - loss: 0.7718 - val_accuracy: 0.5263 - val_loss: 0.7891\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 626ms/step - accuracy: 0.5413 - loss: 0.8801 - val_accuracy: 0.5263 - val_loss: 0.7488\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 593ms/step - accuracy: 0.5573 - loss: 0.8776 - val_accuracy: 0.5263 - val_loss: 0.7349\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 409ms/step - accuracy: 0.5814 - loss: 0.8395 - val_accuracy: 0.5526 - val_loss: 0.7082\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.5995 - loss: 0.7995 - val_accuracy: 0.5263 - val_loss: 0.7077\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 399ms/step - accuracy: 0.5901 - loss: 0.7692 - val_accuracy: 0.5526 - val_loss: 0.7538\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.5437 - loss: 0.7972 - val_accuracy: 0.5526 - val_loss: 0.7818\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 439ms/step - accuracy: 0.6122 - loss: 0.7251 - val_accuracy: 0.5000 - val_loss: 0.7575\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 322ms/step - accuracy: 0.5838 - loss: 0.7848 - val_accuracy: 0.5263 - val_loss: 0.7169\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 310ms/step - accuracy: 0.5746 - loss: 0.7615 - val_accuracy: 0.4737 - val_loss: 0.8227\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 439ms/step - accuracy: 0.5292 - loss: 0.8570 - val_accuracy: 0.4737 - val_loss: 0.8268\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 307ms/step - accuracy: 0.5520 - loss: 0.6975 - val_accuracy: 0.5000 - val_loss: 0.8106\n",
            "2/2 - 0s - 178ms/step - accuracy: 0.5000 - loss: 0.8106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 0.5\n",
            "Model training completed. Validation accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "import os\n",
        "from audiomentations import Compose, AddBackgroundNoise, Shift, PitchShift, TimeStretch\n",
        "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "BACKGROUND_NOISE_PATH = '/content/drive/MyDrive/type3/data/'  # Added for audio augmentation\n",
        "\n",
        "# Data augmentation setup\n",
        "augment = Compose([\n",
        "    AddBackgroundNoise(sounds_path=BACKGROUND_NOISE_PATH, p=0.5),\n",
        "    Shift(p=0.5),\n",
        "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5)\n",
        "])\n",
        "\n",
        "# Load Wav2Vec2 model and processor\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def extract_features(file_path, max_pad_len=128):\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File does not exist: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None, mono=True, res_type='kaiser_fast', duration=5)\n",
        "\n",
        "        if audio is None or len(audio) == 0:\n",
        "            print(f\"Unable to load audio from file: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=128, fmax=sample_rate/2)\n",
        "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "        # Padding or trimming\n",
        "        if spectrogram.shape[1] < max_pad_len:\n",
        "            pad_width = max_pad_len - spectrogram.shape[1]\n",
        "            spectrogram = np.pad(spectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            spectrogram = spectrogram[:, :max_pad_len]\n",
        "\n",
        "        # Flatten the spectrogram for the model\n",
        "        spectrogram = spectrogram.flatten()  # Change this line\n",
        "\n",
        "        # Return as a dictionary\n",
        "        return {'input_values': torch.tensor(spectrogram, dtype=torch.float32)}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while parsing file: {file_path}\")\n",
        "        print(f\"Error details: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_data(csv_path):\n",
        "    df = pd.read_csv(csv_path, sep='\\t')\n",
        "    print(f\"Loaded dataframe shape: {df.shape}\")\n",
        "    print(df.columns)  # Print column names\n",
        "    print(df.head())   # Print first few rows\n",
        "    return df\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "    features = []\n",
        "    for index, row in df.iterrows():\n",
        "        file_path = row['path']\n",
        "        class_label = row['label']\n",
        "        data = extract_features(file_path)\n",
        "        if data is not None:\n",
        "            features.append([data, class_label])\n",
        "        else:\n",
        "            print(f\"Skipping file due to extraction error: {file_path}\")\n",
        "\n",
        "    print(f\"Processed {len(features)} files successfully out of {len(df)} total files\")\n",
        "    return features\n",
        "\n",
        "\n",
        "def prepare_dataset(features):\n",
        "    if not features:\n",
        "        raise ValueError(\"No features were successfully extracted from the dataset.\")\n",
        "\n",
        "    X = np.array([feature[0] for feature in features])\n",
        "    y = np.array([feature[1] for feature in features])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    print(f\"Prepared dataset shapes: X: {X.shape}, y: {y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train, epochs=10, batch_size=32):\n",
        "    # Concatenate the input tensors\n",
        "    train_inputs = torch.cat([item['input_values'].unsqueeze(0) for item in X_train])\n",
        "    train_labels = torch.tensor(y_train)\n",
        "\n",
        "    # Create a DataLoader\n",
        "    train_dataset = torch.utils.data.TensorDataset(train_inputs, train_labels)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(epochs):\n",
        "        for batch in train_loader:\n",
        "            inputs, labels = batch\n",
        "            # Ensure the input is of shape [batch_size, sequence_length]\n",
        "            inputs = inputs.squeeze(1)\n",
        "            outputs = model(inputs).logits\n",
        "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Ensure X_test is concatenated correctly from the 'input_values' in the same way as X_train\n",
        "    test_inputs = torch.cat([item['input_values'].unsqueeze(0) for item in X_test])  # Concatenate input tensors\n",
        "    test_labels = torch.tensor(y_test)  # Convert labels to tensor\n",
        "\n",
        "    # Ensure the input dimensions are correct (shape: [batch_size, sequence_length])\n",
        "    test_inputs = test_inputs.squeeze(1)\n",
        "\n",
        "    # Create a DataLoader for testing\n",
        "    test_dataset = torch.utils.data.TensorDataset(test_inputs, test_labels)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs, labels = batch\n",
        "            outputs = model(inputs).logits\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "            total_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    test_accuracy = total_correct / len(X_test)\n",
        "    print(f'Test accuracy: {test_accuracy}')\n",
        "    return test_accuracy\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    train_df = load_data('/content/drive/MyDrive/type3/data/train_dm.csv')\n",
        "    val_df = load_data('/content/drive/MyDrive/type3/data/valid_dm.csv')\n",
        "\n",
        "    # Preprocess data\n",
        "    train_features = preprocess_data(train_df)\n",
        "    val_features = preprocess_data(val_df)\n",
        "\n",
        "    # Prepare datasets\n",
        "    try:\n",
        "        X_train, y_train = prepare_dataset(train_features)\n",
        "        X_val, y_val = prepare_dataset(val_features)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error preparing dataset: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "    # Train the model\n",
        "    model = train_model(model, X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_accuracy = evaluate_model(model, X_val, y_val)\n",
        "\n",
        "    # Save the model\n",
        "    model.save_pretrained('wav2vec2_audio_classifier_model')\n",
        "\n",
        "    print(f'Model training completed. Validation accuracy: {val_accuracy}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3vPIRgDcf_z",
        "outputId": "7da56f1e-74fd-42c6-d354-95a13141a208"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataframe shape: (268, 3)\n",
            "Index(['file', 'label', 'path'], dtype='object')\n",
            "              file     label  \\\n",
            "0  JeanneLittle_10  dementia   \n",
            "1  TrevorPeacock_5  dementia   \n",
            "2  RonaldReagan_10  dementia   \n",
            "3   RonaldReagan_5  dementia   \n",
            "4  woodydurham_0_2  dementia   \n",
            "\n",
            "                                                path  \n",
            "0  /content/drive/My Drive/type3/data/dementia/Je...  \n",
            "1  /content/drive/My Drive/type3/data/dementia/Tr...  \n",
            "2  /content/drive/My Drive/type3/data/dementia/Ro...  \n",
            "3  /content/drive/My Drive/type3/data/dementia/Ro...  \n",
            "4  /content/drive/My Drive/type3/data/dementia/Wo...  \n",
            "Loaded dataframe shape: (56, 3)\n",
            "Index(['file', 'label', 'path'], dtype='object')\n",
            "               file     label  \\\n",
            "0   EstelleGetty_15  dementia   \n",
            "1      CaseyKasem_5  dementia   \n",
            "2     CaseyKasem_15  dementia   \n",
            "3  JimmyFratianno_0  dementia   \n",
            "4       JoeConley_0  dementia   \n",
            "\n",
            "                                                path  \n",
            "0  /content/drive/My Drive/type3/data/dementia/Es...  \n",
            "1  /content/drive/My Drive/type3/data/dementia/Ca...  \n",
            "2  /content/drive/My Drive/type3/data/dementia/Ca...  \n",
            "3  /content/drive/My Drive/type3/data/dementia/Ji...  \n",
            "4  /content/drive/My Drive/type3/data/dementia/Jo...  \n",
            "Processed 268 files successfully out of 268 total files\n",
            "Processed 56 files successfully out of 56 total files\n",
            "Prepared dataset shapes: X: (268,), y: (268,)\n",
            "Prepared dataset shapes: X: (56,), y: (56,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6071428571428571\n",
            "Model training completed. Validation accuracy: 0.6071428571428571\n"
          ]
        }
      ]
    }
  ]
}